{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo Autoencoders.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Ejemplo de Autoencoder**\n",
        "\n",
        "# **Stacking Autoencoders**\n",
        "\n",
        "\n",
        "# **Declaracion de los import**"
      ],
      "metadata": {
        "id": "l7knaY8jp488"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "metadata": {
        "id": "GjJxVNIqqQ-W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La ultima linea del import se encarga de descargar el conjunto de datos Mnist, este es devuelto en dos pares un conjunto para el entrenamiento y el otro conjunto de pruebas, en este caso los labels no son necesarios por ende se cargan de manera anonima \"_\" pero es necesaria para usar la funcion.\n",
        "\n",
        "# **Preprocesar Datos**\n"
      ],
      "metadata": {
        "id": "n_UJ0jfUqtO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype(np.float32) / 255.0\n",
        "x_test = x_test.astype(np.float32) / 255.0\n",
        "noise_rate = 0.05"
      ],
      "metadata": {
        "id": "3FKSpLLerXnI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estandarizamos los datos en valores en 0 y 1, ademas se crear una variable de ruido"
      ],
      "metadata": {
        "id": "WHOx5T8Lrq-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_noisy = x_train + noise_rate * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_rate * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "x_train_noisy = np.clip(x_train_noisy, 0.0, 1.0)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0.0, 1.0)"
      ],
      "metadata": {
        "id": "HrAy-MmUr9UF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se indtroduce el ruido en una copia del conjunto de datos, luego de esto se verifica con las ultimas  dos lineas que quede estandarizado con valores entre 0 y 1.\n",
        "\n",
        "Ahora nuestras matrices posee los siguientes valores:\n",
        "(60000, 28, 28) y (10000, 28, 28) en (60000, 784) y (10000, 784)\n",
        "respectivamente."
      ],
      "metadata": {
        "id": "ep37_H6istp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "x_train_noisy = x_train_noisy.reshape((len(x_train_noisy), np.prod(x_train_noisy.shape[1:])))\n",
        "x_test_noisy = x_test_noisy.reshape((len(x_test_noisy), np.prod(x_test_noisy.shape[1:])))\n",
        "assert x_train_noisy.shape[1] == x_test_noisy.shape[1]"
      ],
      "metadata": {
        "id": "zYQJIOVKtFR2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se remoldean los conjuntos de datos  en las primeras 4 filas, luego se verifica que los conjuntos de datos  de \"X_train_noisy\" y X_test_noisy\" poseen el mismo tamaño, ya que de no ser asi la funcion va a crashear. Una vez prerpocesados los datos pasamos a crear el autoencoder.\n",
        "\n",
        "\n",
        "# **Creamos el Autoencoder**\n"
      ],
      "metadata": {
        "id": "HDJeflt4tKrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(x_train_noisy.shape[1],))\n",
        "encode1 = Dense(128, activation=tf.keras.activations.relu)(inputs)\n",
        "encode2 = Dense(64, activation=tf.keras.activations.tanh)(encode1)\n",
        "encode3 = Dense(32, activation=tf.keras.activations.relu)(encode2)\n",
        "decode3 = Dense(64, activation=tf.keras.activations.relu)(encode3)\n",
        "decode2 = Dense(128, activation=tf.keras.activations.sigmoid)(decode3)\n",
        "decode1 = Dense(x_train_noisy.shape[1], activation=tf.keras.activations.relu)(decode2)"
      ],
      "metadata": {
        "id": "FjKVYlAfuB9y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea la entrada y lka salidad con el \"x_train_noisy\", y se han creado vairas capas de diferente tamaño ademas de varios activadores, con estos se puede jugar y variarlos segun se desee.\n",
        "\n",
        "# **Contruimos el Modelo**"
      ],
      "metadata": {
        "id": "k9OdscqLvjDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Model(inputs, decode1)\n",
        "autoencoder.compile(optimizer=\"adam\", loss='mean_squared_error' , metrics=['accuracy'])\n",
        "autoencoder.fit(x_train_noisy,x_train_noisy,batch_size=256,epochs=50,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF5lO6zewGYq",
        "outputId": "2d616bb9-5c02-4151-cdcd-f44cff91f677"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0547 - accuracy: 0.0030\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0293 - accuracy: 0.0033\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0241 - accuracy: 0.0041\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0216 - accuracy: 0.0057\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0200 - accuracy: 0.0061\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0187 - accuracy: 0.0065\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0178 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0170 - accuracy: 0.0075\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0165 - accuracy: 0.0073\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0161 - accuracy: 0.0078\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0157 - accuracy: 0.0086\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0153 - accuracy: 0.0082\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0147 - accuracy: 0.0085\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0144 - accuracy: 0.0083\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0142 - accuracy: 0.0081\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0140 - accuracy: 0.0087\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0138 - accuracy: 0.0085\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0136 - accuracy: 0.0090\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0134 - accuracy: 0.0092\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0133 - accuracy: 0.0092\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0132 - accuracy: 0.0091\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0130 - accuracy: 0.0094\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0129 - accuracy: 0.0090\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0128 - accuracy: 0.0095\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0127 - accuracy: 0.0094\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0126 - accuracy: 0.0101\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0125 - accuracy: 0.0099\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0124 - accuracy: 0.0095\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0123 - accuracy: 0.0098\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0122 - accuracy: 0.0099\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0121 - accuracy: 0.0099\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0120 - accuracy: 0.0100\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0119 - accuracy: 0.0100\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0118 - accuracy: 0.0104\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0118 - accuracy: 0.0107\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0117 - accuracy: 0.0108\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0116 - accuracy: 0.0106\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0116 - accuracy: 0.0106\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0115 - accuracy: 0.0110\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0115 - accuracy: 0.0106\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0114 - accuracy: 0.0110\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0114 - accuracy: 0.0113\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0113 - accuracy: 0.0110\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0113 - accuracy: 0.0114\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0112 - accuracy: 0.0113\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0112 - accuracy: 0.0111\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0112 - accuracy: 0.0111\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0111 - accuracy: 0.0111\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0111 - accuracy: 0.0110\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0111 - accuracy: 0.0110\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe34c07b10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se entreno el modelo.Ahora vamos a evaluar y predecir el modelo.\n",
        "\n",
        "# **Evaluacion del Modelo**"
      ],
      "metadata": {
        "id": "6vRmBz7Ayv8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = autoencoder.evaluate(x_test_noisy, x_test, verbose=1)\n",
        "print()\n",
        "print(\"%s:%.2f%%\" % (autoencoder.metrics_names[1], metrics[1]*100))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRJEzFbOzLXp",
        "outputId": "e54a6de9-fd25-4509-8311-36964d99020f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0102 - accuracy: 0.0128\n",
            "\n",
            "accuracy:1.28%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predecimos el Modelo**"
      ],
      "metadata": {
        "id": "t6q-8Pbi05cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = autoencoder.predict(x_test)\n",
        "all_AE_weights_shapes = [x.shape for x in autoencoder.get_weights()]\n",
        "print(all_AE_weights_shapes)\n",
        "ww=len(all_AE_weights_shapes)\n",
        "deeply_encoded_MNIST_weight_matrix = autoencoder.get_weights()[int((ww/2))]\n",
        "print(deeply_encoded_MNIST_weight_matrix.shape)\n",
        "autoencoder.save_weights(\"all_AE_weights.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veF6A1I3077R",
        "outputId": "2deb8f6e-20a5-4d58-db82-c7e85478c700"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(784, 128), (128,), (128, 64), (64,), (64, 32), (32,), (32, 64), (64,), (64, 128), (128,), (128, 784), (784,)]\n",
            "(32, 64)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La matriz resultante se almacena en la variable \"deep_encoded_MNIST\n",
        "_weight_matrix\", la cual  contiene los pesos entrenados para la capa intermedia\n",
        "del codificador automático apilado, y esto luego debe alimentarse a un codificador completamente conectado\n",
        "red neuronal junto con las etiquetas (las que descartamos). Esta matriz de peso\n",
        "es una representación distribuida del conjunto de datos original. También se incluye una copia de todos los pesos.\n",
        "guardado para su uso posterior en un archivo H5. También se ha añadido una variable resultados para hacer\n",
        "predicciones con el codificador automático."
      ],
      "metadata": {
        "id": "Ny9k767H1QHt"
      }
    }
  ]
}