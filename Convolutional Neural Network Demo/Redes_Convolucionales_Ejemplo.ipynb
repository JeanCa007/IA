{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Redes Convolucionales**\n",
        "\n",
        "Las Redes neuronales convolucionales son  un tipo de redes neuronales artificiales  donde las «neuronas»  corresponden a campos receptivos de una manera muy similar a las neuronas en la corteza visual primaria (V1) de un cerebro biológico.  Este tipo de red es una variación de un perceptrón multicapa, sin embargo, debido a que su aplicación es realizada en matrices bidimensionales, son muy efectivas para tareas de visión artificial, como en la clasificación y segmentación de imágenes, entre otras aplicaciones.\n",
        "\n",
        "# **Cómo Funcionan**\n",
        "Las redes neuronales convolucionales consisten en múltiples capas de filtros convolucionales de una o más dimensiones. Después de cada capa, por lo general se añade una función para realizar un mapeo causal no-lineal.\n",
        "\n",
        "Como cualquier  red empleada para clasificación, al principio estas redes tienen una  fase de extracción de características, compuesta de neuronas convolucionales , luego hay una reducción por muestreo y al final tendremos neuronas de perceptrón mas sencillas para realizar la clasificación final sobre las características extraídas.\n",
        "\n",
        "La fase de extracción de características se asemeja al proceso estimulante en las células de la corteza visual. Esta fase se compone de capas alternas de neuronas convolucionales y neuronas de reducción de muestreo. Según progresan los datos a lo largo de esta fase, se disminuye su dimensionalidad, siendo las neuronas en capas lejanas mucho menos sensibles a perturbaciones en los datos de entrada, pero al mismo tiempo siendo estas activadas por características cada vez más complejas.\n",
        "\n",
        "\n",
        "# **Como se logra que una red convolucional aprenda**\n",
        "Las Redes neuronales Convolucionales, CNN  aprenden  a reconocer una diversidad de objetos dentro de imágenes , pero para ello necesitan «entrenarse» de previo con  una cantidad importante de «muestras»  -lease más de 10.000, de ésta forma las neuronas de la red van a poder captar las características únicas -de cada objeto- y a su vez, poder generalizarlo – a esto es lo que se le conoce como el proceso de «aprendizaje de un algoritmo » .   Nuestra red va a poder reconocer por ejemplo un cierto tipo de célula porque ya la ha «visto» anteriormente muchas veces, pero no solo buscará celulas semejantes sino que podrá inferir imagenes que no conozca pero que relaciona y en donde podrían existir similitudes ,  y esta es la parte inteligente del conocimiento"
      ],
      "metadata": {
        "id": "6nyvtbZ8vfH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ejemplo**"
      ],
      "metadata": {
        "id": "6bITYgUsv9CV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Librerias**"
      ],
      "metadata": {
        "id": "ypTeCO6BxAQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "##from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "IIj_kZnrv_V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código implementa una red neuronal convolucional (CNN) usando la librería Keras para trabajar con el dataset MNIST.\n",
        "\n",
        "- **`numpy (np)`**: Usada para realizar operaciones matemáticas avanzadas, como manejar arreglos de datos.\n",
        "- **`keras.models.Sequential`**: Este es un modelo en Keras que permite construir redes neuronales capa por capa.\n",
        "- **`keras.layers.Dense`**: Añade una capa densa (totalmente conectada) a la red. Cada neurona en esta capa se conecta con cada neurona de la capa anterior.\n",
        "- **`keras.layers.Dropout`**: Ayuda a prevenir el sobreajuste eliminando de forma aleatoria un porcentaje de neuronas durante el entrenamiento.\n",
        "- **`keras.layers.Activation`**: Aplica una función de activación a las neuronas, lo que introduce no linealidades en el modelo.\n",
        "- **`keras.layers.Flatten`**: Convierte los datos de entrada en un formato unidimensional (una fila de datos) para conectarse con capas densas.\n",
        "- **`keras.layers.Convolution2D`**: Añade una capa convolucional que es clave para procesar imágenes. Filtra la imagen para detectar características importantes.\n",
        "- **`keras.layers.MaxPooling2D`**: Reduce la dimensionalidad de las imágenes usando agrupamiento máximo (max pooling), lo que disminuye la carga computacional y previene el sobreajuste.\n",
        "- **`keras.utils.to_categorical`**: Convierte etiquetas (por ejemplo, números 0-9 del dataset MNIST) en vectores de una sola categoría (one-hot encoding) para que puedan ser usados en la red neuronal.\n",
        "- **`keras.datasets.mnist`**: El dataset MNIST contiene imágenes en escala de grises de dígitos escritos a mano (28x28 píxeles), muy utilizado para entrenar y probar modelos de reconocimiento de imágenes.\n",
        "- **`tensorflow`**: Keras funciona sobre TensorFlow, que es una librería para computación numérica eficiente.\n",
        "\n",
        "### Hiperparámetros\n",
        "- **Tamaño de las capas**: Al definir capas como `Dense` o `Convolution2D`, hay parámetros como el número de neuronas o filtros que son hiperparámetros del modelo.\n",
        "- **Dropout**: El porcentaje de neuronas que se eliminan durante el entrenamiento (es un hiperparámetro).\n",
        "- **Funciones de activación**: Como `ReLU` o `sigmoid`, que controlan cómo se comporta cada neurona."
      ],
      "metadata": {
        "id": "wrtgsdLnpmdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cargar Data**"
      ],
      "metadata": {
        "id": "mJGtMYIIxmpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_samples, train_labels), (test_samples,test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM-yjTChxl0N",
        "outputId": "e06ecc79-1afb-4e65-b05f-dc3438298d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta línea de código carga el dataset MNIST en dos conjuntos de datos: **entrenamiento** y **prueba**\n",
        "\n",
        "\n",
        "### ¿Qué es `mnist.load_data()`?\n",
        "- **`mnist.load_data()`**: Carga el dataset MNIST, que está preprocesado y listo para usar. Contiene 70,000 imágenes de dígitos escritos a mano (28x28 píxeles) en escala de grises, junto con sus etiquetas (0-9, que representan el número en la imagen).\n",
        "\n",
        "### ¿Qué devuelve?\n",
        "Este método devuelve dos tuplas:\n",
        "1. **Datos de entrenamiento**: `(train_samples, train_labels)`\n",
        "   - **`train_samples`**: Es un array con las imágenes de entrenamiento (60,000 muestras). Cada muestra es una matriz de 28x28 píxeles.\n",
        "   - **`train_labels`**: Son las etiquetas correspondientes a cada imagen de entrenamiento. Cada etiqueta es un número entre 0 y 9 que representa el dígito escrito en la imagen.\n",
        "  \n",
        "2. **Datos de prueba**: `(test_samples, test_labels)`\n",
        "   - **`test_samples`**: Es un array con 10,000 imágenes de prueba. Estas imágenes se usan para verificar qué tan bien ha aprendido el modelo.\n",
        "   - **`test_labels`**: Son las etiquetas que corresponden a las imágenes de prueba. Ayudan a medir la precisión del modelo después del entrenamiento.\n",
        "\n",
        "### Ejemplo visual:\n",
        "Supongamos que cargas una imagen de entrenamiento. Esta se verá como una matriz (de números que representan la intensidad de los píxeles):\n",
        "\n",
        "```python\n",
        "train_samples[0]\n",
        "```\n",
        "Esto daría como resultado una matriz de 28x28, similar a:\n",
        "\n",
        "```\n",
        "array([[  0,   0,   0, ...,   0,   0,   0],\n",
        "       [  0,   0,   0, ...,   0,   0,   0],\n",
        "       ...,\n",
        "       [  0,   0,   0, ...,   0,   0,   0],\n",
        "       [  0,   0,   0, ...,   0,   0,   0]])\n",
        "```\n",
        "\n",
        "Aquí, los valores representan los niveles de gris de cada píxel. Las etiquetas asociadas son números como 3, 7, o 1 que indican cuál dígito está en la imagen.\n",
        "\n",
        "### ¿Por qué se separa en entrenamiento y prueba?\n",
        "- **Entrenamiento**: Se usa para enseñar al modelo a reconocer patrones.\n",
        "- **Prueba**: Se utiliza para evaluar el rendimiento del modelo en datos que no ha visto antes, lo que da una buena indicación de qué tan bien funcionaría en el \"mundo real\".\n"
      ],
      "metadata": {
        "id": "vZCgyrcOp7G3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Procesamiento de los Datos (Estandarizacion)**\n"
      ],
      "metadata": {
        "id": "INKTJE7dyFfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = train_samples.reshape(train_samples.shape [0], 28, 28, 1)\n",
        "test_samples = test_samples.reshape(test_samples.shape [0], 28, 28, 1)\n",
        "train_samples = train_samples.astype(np.float32)\n",
        "test_samples = test_samples.astype(np.float32)\n",
        "train_samples = train_samples/255\n",
        "test_samples = test_samples/255"
      ],
      "metadata": {
        "id": "PeXj7dzwyNUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_train_labels = to_categorical(train_labels, 10)\n",
        "c_test_labels = to_categorical(test_labels, 10)"
      ],
      "metadata": {
        "id": "_qkUtXOKz2qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este bloque de código realiza **preprocesamiento** en los datos de imágenes y etiquetas, lo que es crucial para prepararlos antes de entrenar una red neuronal. Vamos a descomponer cada paso:\n",
        "\n",
        "### 1. **Reformatear las imágenes (`reshape`)**:\n",
        "```python\n",
        "train_samples = train_samples.reshape(train_samples.shape[0], 28, 28, 1)\n",
        "test_samples = test_samples.reshape(test_samples.shape[0], 28, 28, 1)\n",
        "```\n",
        "- **`train_samples.reshape(train_samples.shape[0], 28, 28, 1)`**: Aquí, se cambia la forma de los datos de imágenes.\n",
        "   - **`train_samples.shape[0]`**: Es el número de imágenes (60,000 en el set de entrenamiento y 10,000 en el de prueba).\n",
        "   - **`28, 28`**: Mantiene la forma original de cada imagen, que es de 28x28 píxeles.\n",
        "   - **`1`**: Añade una dimensión extra para indicar que cada imagen tiene **1 canal** de color (en este caso, porque son imágenes en escala de grises).\n",
        "\n",
        "¿Por qué hacemos esto? Muchos modelos convolucionales esperan imágenes con una forma `(altura, ancho, canales)`. Para imágenes en color, normalmente los canales serían 3 (rojo, verde y azul). Aquí es 1 porque son imágenes en escala de grises.\n",
        "\n",
        "### 2. **Convertir los valores de píxeles a `float32`**:\n",
        "```python\n",
        "train_samples = train_samples.astype(np.float32)\n",
        "test_samples = test_samples.astype(np.float32)\n",
        "```\n",
        "- **`astype(np.float32)`**: Convierte los valores de los píxeles, que inicialmente son enteros de 8 bits (entre 0 y 255), a números de punto flotante de 32 bits. Esto es necesario porque las operaciones matemáticas durante el entrenamiento del modelo son más eficientes con este tipo de datos.\n",
        "\n",
        "### 3. **Normalizar los valores de los píxeles**:\n",
        "```python\n",
        "train_samples = train_samples / 255\n",
        "test_samples = test_samples / 255\n",
        "```\n",
        "- **División por 255**: Los valores de los píxeles originalmente van de 0 a 255. Dividir por 255 normaliza estos valores, convirtiéndolos a un rango de 0 a 1. Esto es importante porque los modelos de redes neuronales funcionan mejor cuando los datos están normalizados o escalados. La normalización ayuda a que el entrenamiento sea más eficiente y estable.\n",
        "\n",
        "### 4. **Convertir las etiquetas en one-hot encoding**:\n",
        "```python\n",
        "c_train_labels = to_categorical(train_labels, 10)\n",
        "c_test_labels = to_categorical(test_labels, 10)\n",
        "```\n",
        "- **`to_categorical(train_labels, 10)`**: Esta función convierte las etiquetas originales (que son enteros entre 0 y 9) en vectores **one-hot encoded**. Esto es necesario porque el modelo necesita las etiquetas en un formato que represente cada categoría como un vector binario.\n",
        "   - Ejemplo: Si la etiqueta original era `3`, se convierte en `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`.\n",
        "   - **`10`**: El número total de categorías posibles (dígitos del 0 al 9).\n",
        "\n",
        "### ¿Por qué es necesario one-hot encoding?\n",
        "Las redes neuronales no trabajan directamente con etiquetas numéricas como `3` o `7`. Usar **one-hot encoding** permite que la red aprenda a clasificar los datos en diferentes clases de una manera más eficiente.\n",
        "\n",
        "### Resumen:\n",
        "1. **Reformateo** de las imágenes para que incluyan un canal de color.\n",
        "2. **Conversión** de los valores de los píxeles a `float32`.\n",
        "3. **Normalización** de los valores de los píxeles a un rango de 0 a 1.\n",
        "4. **Conversión de etiquetas** a vectores one-hot.\n",
        "\n",
        "Esto deja los datos en un formato listo para ser ingresado en un modelo de red neuronal convolucional para su entrenamiento."
      ],
      "metadata": {
        "id": "gRD0lmjnqZhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crear  el Modelo**"
      ],
      "metadata": {
        "id": "ZaA8D38uz9gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convnet = Sequential()\n",
        "convnet.add(Convolution2D(32, 4, 4, activation=tf.keras.activations.relu, input_shape=(28,28,1)))\n",
        "convnet.add(MaxPooling2D(pool_size=(2,2)))\n",
        "convnet.add(Convolution2D(32, 3, 3, activation=tf.keras.activations.relu))\n",
        "convnet.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))\n",
        "convnet.add(Dropout(0.3))\n",
        "convnet.add(Flatten())\n",
        "convnet.add(Dense(10, activation=tf.keras.activations.softmax))"
      ],
      "metadata": {
        "id": "w0HyJ-Ed0AKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd69780-4e62-4de5-9163-3eab9023eec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define un modelo de **red neuronal convolucional (CNN)** usando Keras.\n",
        "\n",
        "### 1. **Crear un modelo secuencial**:\n",
        "```python\n",
        "convnet = Sequential()\n",
        "```\n",
        "- **`Sequential()`**: Este es un modelo de Keras que permite construir la red agregando capas de manera secuencial. Cada capa se añade una tras otra en un flujo continuo de datos.\n",
        "\n",
        "### 2. **Primera capa convolucional (`Convolution2D`)**:\n",
        "```python\n",
        "convnet.add(Convolution2D(32, 4, 4, activation=tf.keras.activations.relu, input_shape=(28,28,1)))\n",
        "```\n",
        "- **`Convolution2D(32, 4, 4)`**:\n",
        "  - **32**: El número de **filtros** o **kernels** que se aplicarán a la imagen. Estos detectan características importantes en la imagen como bordes o esquinas.\n",
        "  - **4, 4**: El tamaño del **kernel** (una pequeña matriz de 4x4). Estos kernels se mueven por toda la imagen para identificar patrones locales.\n",
        "- **`activation=tf.keras.activations.relu`**: Usa la función de activación **ReLU (Rectified Linear Unit)**, que transforma los valores negativos a 0 y deja pasar los valores positivos. Esto ayuda a que el modelo aprenda de manera más eficiente.\n",
        "- **`input_shape=(28,28,1)`**: Especifica la forma de los datos de entrada:\n",
        "  - **28, 28**: Dimensiones de las imágenes (28x28 píxeles).\n",
        "  - **1**: Número de canales (1 porque son imágenes en escala de grises).\n",
        "\n",
        "### 3. **Primera capa de agrupación (Max Pooling)**:\n",
        "```python\n",
        "convnet.add(MaxPooling2D(pool_size=(2,2)))\n",
        "```\n",
        "- **`MaxPooling2D(pool_size=(2,2))`**: Esta capa reduce la resolución de la imagen usando una técnica llamada **max pooling**.\n",
        "  - **`pool_size=(2,2)`**: Toma bloques de 2x2 píxeles y solo mantiene el valor máximo de cada bloque. Esto reduce el tamaño de la imagen a la mitad (de 28x28 a 14x14), lo que ayuda a reducir la cantidad de parámetros y el costo computacional, además de enfocarse en las características más importantes.\n",
        "\n",
        "### 4. **Segunda capa convolucional**:\n",
        "```python\n",
        "convnet.add(Convolution2D(32, 3, 3, activation=tf.keras.activations.relu))\n",
        "```\n",
        "- Similar a la primera capa convolucional, pero ahora:\n",
        "  - **32 filtros** de tamaño **3x3** se aplican a la imagen reducida (14x14).\n",
        "  - El objetivo es extraer más características de la imagen, pero con un kernel más pequeño para captar detalles más específicos.\n",
        "\n",
        "### 5. **Segunda capa de agrupación (Max Pooling) con relleno (`padding='same'`)**:\n",
        "```python\n",
        "convnet.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))\n",
        "```\n",
        "- **`MaxPooling2D((2,2), strides=(2,2))`**: Reduce nuevamente la resolución de la imagen (ahora de 14x14 a 7x7), manteniendo el valor máximo de cada bloque de 2x2 píxeles.\n",
        "- **`padding='same'`**: Asegura que el tamaño de salida de la capa no se reduzca demasiado, añadiendo ceros alrededor de la imagen si es necesario para mantener las dimensiones correctas.\n",
        "\n",
        "### 6. **Dropout para prevenir sobreajuste**:\n",
        "```python\n",
        "convnet.add(Dropout(0.3))\n",
        "```\n",
        "- **`Dropout(0.3)`**: Durante el entrenamiento, elimina aleatoriamente el 30% de las neuronas para evitar que el modelo se ajuste demasiado a los datos de entrenamiento (sobreajuste). Esto ayuda a que el modelo generalice mejor en datos nuevos.\n",
        "\n",
        "### 7. **Aplanar la imagen**:\n",
        "```python\n",
        "convnet.add(Flatten())\n",
        "```\n",
        "- **`Flatten()`**: Convierte la salida bidimensional (7x7x32) en un vector unidimensional. Es decir, transforma las imágenes en una sola fila de datos que puede ser usada en capas completamente conectadas (densas).\n",
        "   - Por ejemplo, si tienes una salida de tamaño 7x7 con 32 filtros, se convierte en un vector de tamaño `7*7*32 = 1568` elementos.\n",
        "\n",
        "### 8. **Capa densa con 10 neuronas y activación softmax**:\n",
        "```python\n",
        "convnet.add(Dense(10, activation=tf.keras.activations.softmax))\n",
        "```\n",
        "- **`Dense(10)`**: Añade una capa **densa** con 10 neuronas. Esta es la capa de salida, con 10 neuronas que corresponden a las 10 posibles clases (dígitos del 0 al 9).\n",
        "- **`activation=tf.keras.activations.softmax`**: La función **softmax** convierte las salidas de la red en probabilidades (valores entre 0 y 1) que suman 1. Esto se usa en la clasificación multiclase para predecir a qué clase pertenece cada imagen.\n",
        "\n",
        "### Resumen:\n",
        "- El modelo comienza procesando imágenes con capas convolucionales, extrayendo características clave como bordes y texturas.\n",
        "- Luego, reduce la dimensionalidad con max pooling para hacer el modelo más eficiente.\n",
        "- Un dropout se usa para evitar el sobreajuste.\n",
        "- La imagen es aplanada y pasada a una capa densa final que genera 10 probabilidades, una para cada dígito (0-9).\n",
        "\n",
        "Este modelo está diseñado para clasificar las imágenes de dígitos del dataset MNIST, usando técnicas como convolución, pooling y dropout para mejorar el rendimiento."
      ],
      "metadata": {
        "id": "Bzlp7Ox_qw65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compilar Modelo**"
      ],
      "metadata": {
        "id": "9m5919vv18Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convnet.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                optimizer='sgd',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Od9rL59j19O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta línea de código compila el modelo `convnet`, lo que significa que se configuran tres aspectos clave: la **función de pérdida**, el **optimizador**, y las **métricas** que se usarán para evaluar el rendimiento del modelo durante el entrenamiento.\n",
        "\n",
        "### 1. **Función de pérdida** (`loss`):\n",
        "```python\n",
        "loss=tf.keras.losses.MeanSquaredError()\n",
        "```\n",
        "- **`MeanSquaredError()`**: Es la **pérdida de error cuadrático medio**. Esta función calcula la diferencia al cuadrado entre las predicciones del modelo y los valores reales (etiquetas).\n",
        "  - Para cada salida de la red, se calcula la diferencia entre la salida predicha y la etiqueta verdadera, se eleva al cuadrado, y luego se promedian todas las diferencias. Cuanto menor sea este valor, mejor es la predicción del modelo.\n",
        "  \n",
        "Aunque **`MeanSquaredError`** se utiliza comúnmente en problemas de regresión, en problemas de clasificación, como este, suele ser más común usar **`CategoricalCrossentropy`** o **`SparseCategoricalCrossentropy`**, ya que manejan mejor los problemas de clasificación con etiquetas categóricas. Podrías considerar cambiar la función de pérdida si ves que el modelo no está funcionando bien.\n",
        "\n",
        "### 2. **Optimizador** (`optimizer`):\n",
        "```python\n",
        "optimizer='sgd'\n",
        "```\n",
        "- **`sgd`**: Es el **Descenso por Gradiente Estocástico (Stochastic Gradient Descent)**, que ajusta los pesos del modelo minimizando la función de pérdida.\n",
        "  - **Cómo funciona**: `SGD` actualiza los pesos del modelo usando el gradiente de la función de pérdida con respecto a cada peso. En cada paso del entrenamiento, se realiza una pequeña actualización de los pesos para acercarse al valor mínimo de la función de pérdida, lo que mejora la precisión del modelo.\n",
        "  - Este optimizador es simple pero puede ser lento en converger al mínimo global. Otros optimizadores como **Adam** son más populares para entrenar redes neuronales debido a su eficiencia y ajustes automáticos del tamaño de los pasos.\n",
        "\n",
        "### 3. **Métricas** (`metrics`):\n",
        "```python\n",
        "metrics=['accuracy']\n",
        "```\n",
        "- **`accuracy`**: Es la **precisión** del modelo, que mide el porcentaje de predicciones correctas. Se calcula dividiendo el número de predicciones correctas por el número total de predicciones.\n",
        "  - Es una métrica útil en problemas de clasificación como este, ya que indica qué tan bien el modelo está prediciendo las etiquetas correctas.\n",
        "\n",
        "### Resumen de la compilación:\n",
        "- **Función de pérdida (`MeanSquaredError`)**: Calcula qué tan malas son las predicciones del modelo en comparación con las etiquetas verdaderas. Para este tipo de clasificación, sería más adecuado usar **`CategoricalCrossentropy`**.\n",
        "- **Optimizador (`sgd`)**: Ajusta los pesos del modelo gradualmente usando el descenso por gradiente estocástico.\n",
        "- **Métrica (`accuracy`)**: Evalúa el rendimiento del modelo en términos de precisión, es decir, qué tan bien predice las clases correctas.\n",
        "\n"
      ],
      "metadata": {
        "id": "zgSYxFWerAV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenar Modelo**"
      ],
      "metadata": {
        "id": "ShVCw2zl3uAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convnet.fit(train_samples, c_train_labels, batch_size=32, epochs=20, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPAe-snc3vzv",
        "outputId": "2378278e-ff61-486a-a30d-170ffda67d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1440 - loss: 0.0897\n",
            "Epoch 2/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1723 - loss: 0.0895\n",
            "Epoch 3/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.1928 - loss: 0.0893\n",
            "Epoch 4/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2065 - loss: 0.0891\n",
            "Epoch 5/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2205 - loss: 0.0888\n",
            "Epoch 6/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2354 - loss: 0.0884\n",
            "Epoch 7/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2447 - loss: 0.0880\n",
            "Epoch 8/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2546 - loss: 0.0874\n",
            "Epoch 9/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2666 - loss: 0.0866\n",
            "Epoch 10/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2690 - loss: 0.0857\n",
            "Epoch 11/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.2715 - loss: 0.0847\n",
            "Epoch 12/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.2886 - loss: 0.0834\n",
            "Epoch 13/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3010 - loss: 0.0819\n",
            "Epoch 14/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3245 - loss: 0.0803\n",
            "Epoch 15/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3496 - loss: 0.0786\n",
            "Epoch 16/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3722 - loss: 0.0769\n",
            "Epoch 17/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.3922 - loss: 0.0754\n",
            "Epoch 18/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.4151 - loss: 0.0738\n",
            "Epoch 19/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.4270 - loss: 0.0725\n",
            "Epoch 20/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4386 - loss: 0.0713\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dcabc37bac0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este comando entrena el modelo `convnet` usando los datos de entrenamiento (`train_samples` y `c_train_labels`).\n",
        "\n",
        "### 1. **`train_samples` y `c_train_labels`**:\n",
        "- **`train_samples`**: Este es el conjunto de datos de entrada que contiene las imágenes del dataset MNIST, previamente procesadas y normalizadas. Son imágenes de 28x28 píxeles con 1 canal (escala de grises).\n",
        "- **`c_train_labels`**: Estas son las etiquetas correspondientes a las imágenes, convertidas en **one-hot encoding** (vectores binarios que representan los dígitos del 0 al 9).\n",
        "\n",
        "### 2. **`batch_size=32`**:\n",
        "- **`batch_size`**: Define cuántas muestras (imágenes) se van a usar antes de actualizar los parámetros del modelo en cada paso.\n",
        "  - En este caso, el modelo procesará 32 imágenes a la vez, calculará el error y ajustará los pesos del modelo en función de esas imágenes. Luego tomará las siguientes 32 imágenes, repetirá el proceso, y así sucesivamente.\n",
        "  - Un **tamaño de batch** más pequeño usa menos memoria y actualiza los pesos más frecuentemente, pero es más ruidoso (puede hacer que el modelo oscile). Un tamaño de batch más grande, en cambio, genera actualizaciones más estables, pero consume más memoria.\n",
        "\n",
        "### 3. **`epochs=20`**:\n",
        "- **`epochs`**: Define cuántas veces se va a pasar por todo el conjunto de datos de entrenamiento.\n",
        "  - Aquí, el modelo verá el conjunto de datos completo **20 veces**. Con cada **época**, el modelo ajusta sus pesos basándose en lo que ha aprendido, y cada época es una oportunidad para mejorar su precisión.\n",
        "  - Un número mayor de épocas puede permitir que el modelo aprenda mejor, pero si son demasiadas, existe el riesgo de que el modelo se **sobreajuste** a los datos de entrenamiento (aprenda demasiado bien los datos y no generalice bien para nuevos datos).\n",
        "\n",
        "### 4. **`verbose=1`**:\n",
        "- **`verbose`**: Controla el nivel de detalle que se muestra durante el entrenamiento.\n",
        "  - **`verbose=1`**: Muestra una barra de progreso y estadísticas sobre la pérdida y la precisión al final de cada época.\n",
        "  - Si fuera **`verbose=0`**, no mostraría nada, y **`verbose=2`** mostraría información resumida sin la barra de progreso.\n",
        "\n",
        "### ¿Qué sucede durante el entrenamiento?\n",
        "- El modelo toma 32 imágenes, predice sus etiquetas, y compara las predicciones con las etiquetas verdaderas.\n",
        "- La función de pérdida (en este caso, `MeanSquaredError`) calcula cuán lejos están las predicciones de las etiquetas verdaderas.\n",
        "- El optimizador **SGD** ajusta los pesos del modelo en función del error.\n",
        "- Este proceso se repite hasta que el modelo haya pasado por todas las imágenes del set de entrenamiento (esto es una **época**).\n",
        "- Después de 20 épocas, el entrenamiento finaliza, y el modelo debería haber aprendido a reconocer dígitos con una mayor precisión.\n",
        "\n",
        "### Resumen:\n",
        "Este código entrena la red neuronal convolucional en el conjunto de entrenamiento durante 20 épocas, ajustando los pesos del modelo en bloques de 32 imágenes a la vez. Durante el entrenamiento, el modelo optimiza sus pesos para minimizar la pérdida y mejorar la precisión en la clasificación de los dígitos.\n"
      ],
      "metadata": {
        "id": "3TA0CAvirXXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Probamos el Modelo**"
      ],
      "metadata": {
        "id": "MdNcUcAK48E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = convnet.evaluate(test_samples, c_test_labels, verbose=1)\n",
        "print()\n",
        "print(\"%s: %.2f%%\" % (convnet.metrics_names[1], metrics[1]*100))\n",
        "predictions = convnet.predict(test_samples)\n",
        "print(predictions.shape)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTLp1k1B4-wu",
        "outputId": "8a979eb4-c34d-4d0c-9f31-17ffec0f9c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5114 - loss: 0.0676\n",
            "\n",
            "compile_metrics: 52.78%\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "(10000, 10)\n",
            "[[0.01862566 0.05666417 0.03756529 ... 0.39862356 0.02339912 0.15292904]\n",
            " [0.05240709 0.17731768 0.15686396 ... 0.02918103 0.10544442 0.0335084 ]\n",
            " [0.01960317 0.5679807  0.01891124 ... 0.06900783 0.08568923 0.05771609]\n",
            " ...\n",
            " [0.00780399 0.20290558 0.02186159 ... 0.30895025 0.03543393 0.12439568]\n",
            " [0.01614334 0.10816358 0.02997625 ... 0.34133676 0.03180172 0.13343371]\n",
            " [0.3191295  0.00659287 0.22236691 ... 0.01318071 0.08352403 0.0345929 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código evalúa el rendimiento del modelo entrenado en el conjunto de datos de prueba y realiza predicciones sobre las imágenes de prueba.\n",
        "\n",
        "### 1. **Evaluar el modelo (`evaluate`)**:\n",
        "```python\n",
        "metrics = convnet.evaluate(test_samples, c_test_labels, verbose=1)\n",
        "```\n",
        "- **`convnet.evaluate(test_samples, c_test_labels)`**: Evalúa el modelo usando el conjunto de datos de prueba.\n",
        "  - **`test_samples`**: Las imágenes de prueba que el modelo no ha visto durante el entrenamiento.\n",
        "  - **`c_test_labels`**: Las etiquetas de prueba correspondientes a las imágenes.\n",
        "- **`metrics`**: Contiene los valores de las métricas especificadas durante la compilación del modelo (en este caso, la precisión). La función `evaluate` devuelve la pérdida y las métricas definidas en `convnet.compile`.\n",
        "- **`verbose=1`**: Muestra información durante la evaluación, como el progreso de la evaluación y las métricas.\n",
        "\n",
        "### 2. **Imprimir la precisión (`print`)**:\n",
        "```python\n",
        "print()\n",
        "print(\"%s: %.2f%%\" % (convnet.metrics_names[1], metrics[1]*100))\n",
        "```\n",
        "- **`convnet.metrics_names[1]`**: Obtiene el nombre de la segunda métrica definida durante la compilación (en este caso, `\"accuracy\"`).\n",
        "- **`metrics[1]`**: Obtiene el valor de la precisión del modelo en el conjunto de datos de prueba.\n",
        "- **`metrics[1]*100`**: Convierte la precisión a porcentaje para una mejor interpretación.\n",
        "\n",
        "### 3. **Realizar predicciones (`predict`)**:\n",
        "```python\n",
        "predictions = convnet.predict(test_samples)\n",
        "```\n",
        "- **`convnet.predict(test_samples)`**: Usa el modelo entrenado para hacer predicciones sobre las imágenes de prueba.\n",
        "  - **`test_samples`**: Las imágenes sobre las que queremos hacer predicciones.\n",
        "- **`predictions`**: Es una matriz con la probabilidad de cada clase para cada imagen. Si tienes 10,000 imágenes de prueba y 10 clases, `predictions` será una matriz de forma `(10000, 10)`.\n",
        "\n",
        "### 4. **Imprimir la forma y el contenido de las predicciones (`print`)**:\n",
        "```python\n",
        "print(predictions.shape)\n",
        "print(predictions)\n",
        "```\n",
        "- **`predictions.shape`**: Imprime la forma de la matriz de predicciones, que será `(n_samples, n_classes)`. En este caso, `(10000, 10)`, ya que hay 10,000 imágenes y 10 clases.\n",
        "- **`predictions`**: Imprime el contenido de la matriz de predicciones. Cada fila corresponde a una imagen y cada columna a la probabilidad de que la imagen pertenezca a una de las 10 clases.\n",
        "\n",
        "### Resumen:\n",
        "1. **Evaluación del Modelo**: `convnet.evaluate` mide el rendimiento del modelo en el conjunto de datos de prueba, devolviendo la pérdida y las métricas (como la precisión). Se imprime la precisión como porcentaje.\n",
        "2. **Predicciones**: `convnet.predict` genera probabilidades de clase para cada imagen en el conjunto de prueba. Las probabilidades están en una matriz que se puede usar para interpretar qué clase es más probable para cada imagen.\n",
        "\n",
        "Este código te permite verificar la precisión de tu modelo y ver cómo se comporta en datos nuevos. Además, te da la posibilidad de examinar las probabilidades que el modelo asigna a cada clase para cada imagen de prueba."
      ],
      "metadata": {
        "id": "vJ4uk4AmrlWX"
      }
    }
  ]
}